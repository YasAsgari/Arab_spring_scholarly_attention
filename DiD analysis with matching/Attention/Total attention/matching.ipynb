{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1542f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129dd81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pop_df=pd.read_csv(r'C:\\Users\\Yasaman\\Downloads\\World_bank_population.csv',skiprows=3)\n",
    "pop_df['Country Code']=pop_df['Country Code'].apply(lambda x: x.lower())\n",
    "possible_countries=pop_df.query(\" `2019` >=1000000\")['Country Code'].values\n",
    "\n",
    "excluded_iso3_codes = [\n",
    "    \"IRL\",  # Ireland\n",
    "    \"SSD\",  # South Sudan\n",
    "    \"SDN\",  # Sudan\n",
    "    \"COG\",  # Republic of the Congo\n",
    "    \"COD\",  # Democratic Republic of the Congo\n",
    "    \"GIN\",  # Guinea\n",
    "    \"GNB\",  # Guinea-Bissau\n",
    "    \"GNQ\",  # Equatorial Guinea\n",
    "    \"PNG\",  # Papua New Guinea\n",
    "    \"XKX\",  # Kosovo (unofficial)\n",
    "    \"MNE\",  # Montenegro\n",
    "    \"SRB\",  # Serbia\n",
    "    \"TLS\",   # Timor-Leste\n",
    "    \"GEO\", #Georgia\n",
    "    'SWZ', \n",
    "    'PRK', #North Korea\n",
    "]\n",
    "excluded_iso3_codes=[c.lower() for c in excluded_iso3_codes]\n",
    "\n",
    "\n",
    "possible_iso=list(set(possible_countries)-set(excluded_iso3_codes))\n",
    "df = pd.read_csv(r\"C:\\Users\\Yasaman\\Downloads\\Attention-fractional counting.csv\")\n",
    "df.rename(columns={'aggregated_value': 'count', 'country': 'Mention_country', 'affiliation_country': 'Aff_country'}, inplace=True)\n",
    "df=df[(df['Mention_country'].isin(possible_iso))&(df['Aff_country'].isin(possible_iso))]\n",
    "df = df[df['year'].isin(np.arange(2002, 2020))]\n",
    "Country_list={'Egypt':'EGY', 'Tunisia':'TUN','Libya':'LBY','Syria':'SYR','Yemen':'YEM','Bahrain':'BHR','Jordan':'JOR','Kuwait':'KWT','Morocco':'MAR','Oman':'OMN'}\n",
    "rev_Country_list={Country_list[key]: key for key in Country_list}\n",
    "abbr=[country.lower() for country in Country_list.values()]\n",
    "physical_sciences=['MATH', 'ENGI', 'PHYS', 'COMP', 'MUL']\n",
    "df=df[~df['subjarea'].isin(physical_sciences)]\n",
    "df=df.groupby(['year', 'Mention_country'])['count'].sum().reset_index()\n",
    "\n",
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\Yasaman\\Downloads\\scopus_2024_V1_scholarlymigration_country_enriched.csv\")\n",
    "data=data[data['year'].isin(np.arange(2002, 2020))]\n",
    "data=data[['iso3code', 'incomelevel', 'gdp_per_capita', 'year', 'population', 'region', 'padded_population_of_researchers']].dropna()\n",
    "data.rename(columns={'iso3code':'Mention_country'}, inplace=True)\n",
    "data['Mention_country']=data['Mention_country'].apply(lambda x: x.lower())\n",
    "df=df.merge(data, on=['Mention_country', 'year'], how='outer')\n",
    "df=df[df['Mention_country'].isin(possible_iso)]\n",
    "\n",
    "\n",
    "countries_to_remove=[]\n",
    "for c  in df['Mention_country'].unique():\n",
    "    if ((~df['count'].isna()) & (df['Mention_country'] == c)).sum()<15:\n",
    "        countries_to_remove.append(c)\n",
    "        print(c)\n",
    "\n",
    "print(len(countries_to_remove))\n",
    "\n",
    "\n",
    "# Define the required year range\n",
    "required_years = list(range(2002, 2020))\n",
    "\n",
    "# Get the unique countries\n",
    "unique_countries = df[\"Mention_country\"].unique()\n",
    "\n",
    "# Create a complete DataFrame with all country-year combinations\n",
    "full_data = []\n",
    "for country in unique_countries:\n",
    "    country_data = df[df[\"Mention_country\"] == country]\n",
    "    existing_years = set(country_data[\"year\"])\n",
    "    \n",
    "    for year in required_years:\n",
    "        if year in existing_years:\n",
    "            row = country_data[country_data[\"year\"] == year].iloc[0].to_dict()\n",
    "        else:\n",
    "            row = {\n",
    "                \"year\": year,\n",
    "                \"Mention_country\": country,\n",
    "                \"count\": 0,\n",
    "                \"gdp_per_capita\": np.nan,\n",
    "                \"population\": np.nan,\n",
    "                \"region\": country_data[\"region\"].iloc[0] if not country_data.empty else np.nan,\n",
    "            }\n",
    "        full_data.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_complete = pd.DataFrame(full_data)\n",
    "\n",
    "df_complete['treated']=df_complete['Mention_country'].isin(abbr).astype(int)\n",
    "df_complete['treated_CW']=df_complete['Mention_country'].isin(['yem', 'lby', 'syr']).astype(int)\n",
    "df_complete['treated_GO']=df_complete['Mention_country'].isin(['egy', 'tun']).astype(int)\n",
    "df_complete['treated_GC']=df_complete['Mention_country'].isin(['omn', 'kwt', 'bhr', 'mar','jor']).astype(int)\n",
    "df_complete['post']=df_complete['year'].apply(lambda x: 0 if x>=2002 and x<=2010 else 1 )\n",
    "df_complete['count']=df_complete['count'].fillna(0)\n",
    "df_complete['log_count']=np.log(df_complete['count']+1)\n",
    "\n",
    "df_complete[['region', 'gdp_per_capita', 'population','padded_population_of_researchers']] = df_complete.groupby('Mention_country')[[ 'region', 'gdp_per_capita', 'population','padded_population_of_researchers']].ffill()\n",
    "df_complete[[ 'region', 'gdp_per_capita', 'population','padded_population_of_researchers']] = df_complete.groupby('Mention_country')[[ 'region', 'gdp_per_capita', 'population','padded_population_of_researchers']].bfill()\n",
    "df_complete['log_gdp']=np.log(df_complete['gdp_per_capita'])\n",
    "df_complete['log_population']=np.log(df_complete['population'])\n",
    "df_complete['log_Rpop']=np.log(df_complete['padded_population_of_researchers']+1)\n",
    "df_complete=df_complete[df_complete['Mention_country'].isin(possible_iso)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4c423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pretrend_slopes(df, outcome=\"log_count\"):\n",
    "    results = []\n",
    "    for country, dfg in df[df[\"post\"] == 0].groupby(\"Mention_country\"):\n",
    "        if dfg[\"year\"].nunique() > 1:  # need at least 2 years\n",
    "            X = sm.add_constant(dfg[\"year\"])\n",
    "            y = dfg[outcome]\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            slope = model.params[\"year\"]\n",
    "        else:\n",
    "            slope = None  # not enough years to estimate\n",
    "        results.append({\"country\": country, \"pretrend_slope\": slope})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "slopes_df = compute_pretrend_slopes(df_complete[df_complete[\"post\"] == 0], outcome=\"log_count\")\n",
    "df_complete=pd.merge(df_complete, slopes_df, left_on=\"Mention_country\", right_on=\"country\", how=\"left\").drop(\"country\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0158e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mention_country</th>\n",
       "      <th>treated</th>\n",
       "      <th>log_count</th>\n",
       "      <th>log_gdp</th>\n",
       "      <th>log_population</th>\n",
       "      <th>log_Rpop</th>\n",
       "      <th>pretrend_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.630891</td>\n",
       "      <td>5.708974</td>\n",
       "      <td>17.030284</td>\n",
       "      <td>3.905235</td>\n",
       "      <td>0.183261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ago</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.973515</td>\n",
       "      <td>7.644569</td>\n",
       "      <td>16.820689</td>\n",
       "      <td>4.042117</td>\n",
       "      <td>0.112445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.867380</td>\n",
       "      <td>7.961445</td>\n",
       "      <td>14.909524</td>\n",
       "      <td>5.533527</td>\n",
       "      <td>0.132889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.278234</td>\n",
       "      <td>10.538480</td>\n",
       "      <td>15.480804</td>\n",
       "      <td>7.400455</td>\n",
       "      <td>0.113974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.062080</td>\n",
       "      <td>8.642571</td>\n",
       "      <td>17.490096</td>\n",
       "      <td>10.118671</td>\n",
       "      <td>0.096689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>vnm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.107615</td>\n",
       "      <td>6.688820</td>\n",
       "      <td>18.245700</td>\n",
       "      <td>7.655013</td>\n",
       "      <td>0.126911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>yem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.114453</td>\n",
       "      <td>6.733423</td>\n",
       "      <td>16.906847</td>\n",
       "      <td>5.404255</td>\n",
       "      <td>0.109025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>zaf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.442647</td>\n",
       "      <td>8.611745</td>\n",
       "      <td>17.719030</td>\n",
       "      <td>9.686546</td>\n",
       "      <td>0.089602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>zmb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.768977</td>\n",
       "      <td>6.732118</td>\n",
       "      <td>16.300536</td>\n",
       "      <td>5.897655</td>\n",
       "      <td>0.090594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>zwe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.378426</td>\n",
       "      <td>6.249042</td>\n",
       "      <td>16.330251</td>\n",
       "      <td>6.660403</td>\n",
       "      <td>0.033726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mention_country  treated  log_count    log_gdp  log_population   log_Rpop  \\\n",
       "0               afg      0.0   4.630891   5.708974       17.030284   3.905235   \n",
       "1               ago      0.0   3.973515   7.644569       16.820689   4.042117   \n",
       "2               alb      0.0   3.867380   7.961445       14.909524   5.533527   \n",
       "3               are      0.0   5.278234  10.538480       15.480804   7.400455   \n",
       "4               arg      0.0   7.062080   8.642571       17.490096  10.118671   \n",
       "..              ...      ...        ...        ...             ...        ...   \n",
       "140             vnm      0.0   6.107615   6.688820       18.245700   7.655013   \n",
       "141             yem      1.0   4.114453   6.733423       16.906847   5.404255   \n",
       "142             zaf      0.0   7.442647   8.611745       17.719030   9.686546   \n",
       "143             zmb      0.0   4.768977   6.732118       16.300536   5.897655   \n",
       "144             zwe      0.0   5.378426   6.249042       16.330251   6.660403   \n",
       "\n",
       "     pretrend_slope  \n",
       "0          0.183261  \n",
       "1          0.112445  \n",
       "2          0.132889  \n",
       "3          0.113974  \n",
       "4          0.096689  \n",
       "..              ...  \n",
       "140        0.126911  \n",
       "141        0.109025  \n",
       "142        0.089602  \n",
       "143        0.090594  \n",
       "144        0.033726  \n",
       "\n",
       "[145 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_summ=df_complete.query(\" `year`< 2011 \").groupby('Mention_country')[['treated', 'log_count', 'log_gdp', 'log_population', 'log_Rpop', 'pretrend_slope']].mean().reset_index()\n",
    "pre_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f75861",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_summ=df_complete.query(\" `year`< 2011 \").groupby('Mention_country')[['treated', 'log_count', 'log_gdp', 'log_population', 'log_Rpop', 'pretrend_slope']].mean().reset_index()\n",
    "def zscore_to_bins(s, edges):\n",
    "    z = (s - s.mean())/s.std(ddof=0)  \n",
    "    return pd.cut(z, bins=edges, include_lowest=True)\n",
    "\n",
    "E5 =  [-np.inf, -3, -1.5, -0.75, 0.75, 1.5,  3, np.inf]\n",
    "\n",
    "pre_summ['log_count_bin'] = zscore_to_bins(pre_summ['log_count'], E5)\n",
    "pre_summ['log_gdp_bin'] = zscore_to_bins(pre_summ['log_gdp'], E5)\n",
    "pre_summ['log_population_bin'] = zscore_to_bins(pre_summ['log_population'], E5)\n",
    "pre_summ['log_Rpop_bin'] = zscore_to_bins(pre_summ['log_Rpop'], E5)\n",
    "pre_summ['pretrend_slope_bin'] = zscore_to_bins(pre_summ['pretrend_slope'], E5)\n",
    "\n",
    "\n",
    "strata_cols = [ 'log_count_bin', 'log_population_bin', 'log_Rpop_bin',  'log_gdp_bin']\n",
    "pre_summ['stratum'] = pre_summ[strata_cols].astype(str).agg('|'.join, axis=1)\n",
    "pre_summ=pre_summ.reset_index().rename(columns={'index':'id'}    )\n",
    "# CEM pruning + weights\n",
    "counts = pre_summ.groupby(['stratum','treated'])['id'].count().unstack(fill_value=0)\n",
    "valid_strata = counts[(counts[0] > 0) & (counts[1] > 0)].index\n",
    "matched = pre_summ[pre_summ['stratum'].isin(valid_strata)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0a38ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ago', 'bgr', 'bol', 'cmr', 'cri', 'cub', 'dom', 'dza', 'ecu',\n",
       "       'hnd', 'hti', 'irq', 'kaz', 'kgz', 'lao', 'lbn', 'lka', 'mys',\n",
       "       'ner', 'per', 'pri', 'pry', 'rou', 'rwa', 'sen', 'slv', 'svn',\n",
       "       'tgo', 'tto', 'ukr', 'ven'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched[matched['treated']==0].Mention_country.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e7a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of counts by stratum and treated\n",
    "tab = (matched\n",
    "       .groupby(['stratum','treated'])['id']\n",
    "       .size()\n",
    "       .unstack(fill_value=0)\n",
    "       .rename(columns={0:'n_control', 1:'n_treated'}))\n",
    "\n",
    "# join back by stratum\n",
    "matched = matched.join(tab, on='stratum')\n",
    "\n",
    "matched['cem_w'] = np.where(\n",
    "    matched['treated'] == 1,\n",
    "    1.0,\n",
    "    matched['n_treated'] / matched['n_control']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff14d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.to_csv(r'C:\\Users\\Yasaman\\Arab Spring Paper\\Arab Spring Code\\DiD analysis with matching\\Attention\\Total attention\\matched_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
